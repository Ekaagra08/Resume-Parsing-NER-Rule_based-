{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Custom-Resume-NER.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "126-XSs3AAzZO9SNwYbqgXQA4L5wYsfHY",
      "authorship_tag": "ABX9TyM/xxLSwKwga8WlrTUHiT1d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ekaagra08/Resume-Parsing-NER-Rule_based-/blob/main/Custom_Resume_NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy==2.1.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmgHhmjeOhIF",
        "outputId": "8941b253-fa35-4b07-c733-d34c63be6aa1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spacy==2.1.4\n",
            "  Downloading spacy-2.1.4-cp37-cp37m-manylinux1_x86_64.whl (29.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 29.8 MB 16.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.4) (1.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.4) (2.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.4) (1.19.5)\n",
            "Requirement already satisfied: jsonschema<3.1.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.4) (2.6.0)\n",
            "Collecting plac<1.0.0,>=0.9.6\n",
            "  Downloading plac-0.9.6-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.4) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.4) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.4) (2.23.0)\n",
            "Collecting blis<0.3.0,>=0.2.2\n",
            "  Downloading blis-0.2.4-cp37-cp37m-manylinux1_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 51.4 MB/s \n",
            "\u001b[?25hCollecting thinc<7.1.0,>=7.0.2\n",
            "  Downloading thinc-7.0.8-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 40.3 MB/s \n",
            "\u001b[?25hCollecting preshed<2.1.0,>=2.0.1\n",
            "  Downloading preshed-2.0.1-cp37-cp37m-manylinux1_x86_64.whl (82 kB)\n",
            "\u001b[K     |████████████████████████████████| 82 kB 435 kB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.4) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.4) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.4) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.4) (2021.10.8)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.7/dist-packages (from thinc<7.1.0,>=7.0.2->spacy==2.1.4) (4.62.3)\n",
            "Installing collected packages: preshed, plac, blis, thinc, spacy\n",
            "  Attempting uninstall: preshed\n",
            "    Found existing installation: preshed 3.0.6\n",
            "    Uninstalling preshed-3.0.6:\n",
            "      Successfully uninstalled preshed-3.0.6\n",
            "  Attempting uninstall: plac\n",
            "    Found existing installation: plac 1.1.3\n",
            "    Uninstalling plac-1.1.3:\n",
            "      Successfully uninstalled plac-1.1.3\n",
            "  Attempting uninstall: blis\n",
            "    Found existing installation: blis 0.4.1\n",
            "    Uninstalling blis-0.4.1:\n",
            "      Successfully uninstalled blis-0.4.1\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 2.2.5 requires spacy>=2.2.2, but you have spacy 2.1.4 which is incompatible.\u001b[0m\n",
            "Successfully installed blis-0.2.4 plac-0.9.6 preshed-2.0.1 spacy-2.1.4 thinc-7.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ndf-hboQ0WVn"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "import random\n",
        "import logging\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from spacy.gold import GoldParse\n",
        "from spacy.scorer import Scorer\n",
        "from sklearn.metrics import accuracy_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "!python -m spacy download en_core_web_md\n",
        "import en_core_web_md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQ36dM4S1GID",
        "outputId": "54bef7bb-ebee-48b5-fdd3-32def1aad082"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_md==2.1.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.1.0/en_core_web_md-2.1.0.tar.gz (95.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 95.4 MB 1.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-core-web-md\n",
            "  Building wheel for en-core-web-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-md: filename=en_core_web_md-2.1.0-py3-none-any.whl size=97126236 sha256=679bf6d6758ad33e0b77f126afcfb85c5b28b5c0a195b371fdd7cad687f82837\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-t5b8_j2y/wheels/1a/4e/53/ca2bd8efb94658d2425a0a2d998ffddc2db7ea1378421f8565\n",
            "Successfully built en-core-web-md\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_json_for_spacy(FilePath):\n",
        "    try:\n",
        "      converted_data = []\n",
        "      lines=[]\n",
        "      with open(FilePath, 'r') as f:\n",
        "          lines = f.readlines()\n",
        "\n",
        "      for line in lines:\n",
        "          data = json.loads(line)\n",
        "          text = data['content'].replace(\"\\n\", \" \")\n",
        "          entities = []\n",
        "          data_annotations = data['annotation']\n",
        "          if data_annotations is not None:\n",
        "              for annotation in data_annotations:\n",
        "                  #only a single point in text annotation.\n",
        "                  point = annotation['points'][0]\n",
        "                  labels = annotation['label']\n",
        "                  # handle both list of labels or a single label.\n",
        "                  if not isinstance(labels, list):\n",
        "                      labels = [labels]\n",
        "\n",
        "                  for label in labels:\n",
        "                      point_start = point['start']\n",
        "                      point_end = point['end']\n",
        "                      point_text = point['text']\n",
        "\n",
        "                      lstrip_diff = len(point_text) - len(point_text.lstrip())\n",
        "                      rstrip_diff = len(point_text) - len(point_text.rstrip())\n",
        "                      if lstrip_diff != 0:\n",
        "                          point_start = point_start + lstrip_diff\n",
        "                      if rstrip_diff != 0:\n",
        "                          point_end = point_end - rstrip_diff\n",
        "                      entities.append((point_start, point_end + 1 , label))\n",
        "          \n",
        "          converted_data.append((text, {\"entities\" : entities}))\n",
        "      return converted_data\n",
        "      \n",
        "    except Exception as e:\n",
        "      logging.exception(\"Unable to process \" + FilePath + \"\\n\" + \"error = \" + str(e))\n",
        "      return None    \n",
        "\n",
        "################################################################################################\n",
        "\n",
        "def trim_entity_spans(data: list) -> list:\n",
        "# removes extra white spaces from entity span to prevent overlaping\n",
        "    invalid_span_tokens = re.compile(r'\\s')\n",
        "\n",
        "    cleaned_data = []\n",
        "    for text, annotations in data:\n",
        "        entities = annotations['entities']\n",
        "        valid_entities = []\n",
        "        for start, end, label in entities:\n",
        "            valid_start = start\n",
        "            valid_end = end\n",
        "            while valid_start < len(text) and invalid_span_tokens.match(\n",
        "                    text[valid_start]):\n",
        "                valid_start += 1\n",
        "            while valid_end > 1 and invalid_span_tokens.match(\n",
        "                    text[valid_end - 1]):\n",
        "                valid_end -= 1\n",
        "            valid_entities.append([valid_start, valid_end, label])\n",
        "        cleaned_data.append([text, {'entities': valid_entities}])\n",
        "    \n",
        "    return cleaned_data\n"
      ],
      "metadata": {
        "id": "qVWRtkfMC7ce"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_clean = trim_entity_spans(convert_json_for_spacy(\"/content/drive/MyDrive/Resume Parsing (NER + Rule-based)/traindata.json\"))\n",
        "print(train_data_clean[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UEZQKE4KIzA",
        "outputId": "7d5954de-baad-48f0-ea07-68a8dfdc3066"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Govardhana K Senior Software Engineer  Bengaluru, Karnataka, Karnataka - Email me on Indeed: indeed.com/r/Govardhana-K/ b2de315d95905b68  Total IT experience 5 Years 6 Months Cloud Lending Solutions INC 4 Month • Salesforce Developer Oracle 5 Years 2 Month • Core Java Developer Languages Core Java, Go Lang Oracle PL-SQL programming, Sales Force Developer with APEX.  Designations & Promotions  Willing to relocate: Anywhere  WORK EXPERIENCE  Senior Software Engineer  Cloud Lending Solutions -  Bangalore, Karnataka -  January 2018 to Present  Present  Senior Consultant  Oracle -  Bangalore, Karnataka -  November 2016 to December 2017  Staff Consultant  Oracle -  Bangalore, Karnataka -  January 2014 to October 2016  Associate Consultant  Oracle -  Bangalore, Karnataka -  November 2012 to December 2013  EDUCATION  B.E in Computer Science Engineering  Adithya Institute of Technology -  Tamil Nadu  September 2008 to June 2012  https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN   SKILLS  APEX. (Less than 1 year), Data Structures (3 years), FLEXCUBE (5 years), Oracle (5 years), Algorithms (3 years)  LINKS  https://www.linkedin.com/in/govardhana-k-61024944/  ADDITIONAL INFORMATION  Technical Proficiency:  Languages: Core Java, Go Lang, Data Structures & Algorithms, Oracle PL-SQL programming, Sales Force with APEX. Tools: RADTool, Jdeveloper, NetBeans, Eclipse, SQL developer, PL/SQL Developer, WinSCP, Putty Web Technologies: JavaScript, XML, HTML, Webservice  Operating Systems: Linux, Windows Version control system SVN & Git-Hub Databases: Oracle Middleware: Web logic, OC4J Product FLEXCUBE: Oracle FLEXCUBE Versions 10.x, 11.x and 12.x  https://www.linkedin.com/in/govardhana-k-61024944/', {'entities': [[1749, 1755, 'Companies worked at'], [1696, 1702, 'Companies worked at'], [1417, 1423, 'Companies worked at'], [1356, 1793, 'Skills'], [1209, 1215, 'Companies worked at'], [1136, 1247, 'Skills'], [928, 932, 'Graduation Year'], [858, 889, 'College Name'], [821, 856, 'Degree'], [787, 791, 'Graduation Year'], [744, 750, 'Companies worked at'], [722, 742, 'Designation'], [658, 664, 'Companies worked at'], [640, 656, 'Designation'], [574, 580, 'Companies worked at'], [555, 572, 'Designation'], [470, 493, 'Companies worked at'], [444, 468, 'Designation'], [308, 314, 'Companies worked at'], [234, 240, 'Companies worked at'], [175, 198, 'Companies worked at'], [93, 136, 'Email Address'], [39, 48, 'Location'], [13, 37, 'Designation'], [0, 12, 'Name']]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_spacyNER():\n",
        "\n",
        "  # creating blank eng-language class and add the built-in pipeline components to the pipeline\n",
        "  c_nlp = spacy.blank(\"en\")\n",
        "  if 'ner' not in c_nlp.pipe_names:\n",
        "    ner = c_nlp.create_pipe('ner')\n",
        "    c_nlp.add_pipe(ner,last = True)\n",
        "\n",
        "  # adding custome lables from resume\n",
        "  for _, annotation in train_data_clean:\n",
        "    for ent in annotation.get('entities'):\n",
        "      ner.add_label(ent[2])    \n",
        "\n",
        "  # other pipes to disabled during training\n",
        "  other_pipes = [pipe for pipe in c_nlp.pipe_names if pipe != 'ner']\n",
        "  with c_nlp.disable_pipes(*other_pipes):  # only train NER\n",
        "    optimizer = c_nlp.begin_training()\n",
        "    for itn in range(10):\n",
        "      print(\"Statring iteration \" + str(itn + 1))\n",
        "      random.shuffle(train_data_clean)\n",
        "      losses = {}\n",
        "      for text, annotations in train_data_clean:\n",
        "        c_nlp.update(\n",
        "            [text],  # batch of texts\n",
        "            [annotations],  # batch of annotations\n",
        "            drop=0.2,  # dropout - make it harder to memorise data\n",
        "            sgd=optimizer,  # callable to update weights\n",
        "            losses=losses)\n",
        "      print(losses)\n",
        "  return c_nlp   "
      ],
      "metadata": {
        "id": "nUQL7e93Km32"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = train_spacyNER()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Meashv-zLnpI",
        "outputId": "25770bfc-557b-48f3-d483-a0a903e487df"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statring iteration 1\n",
            "{'ner': 25523.626846685635}\n",
            "Statring iteration 2\n",
            "{'ner': 20646.36639341638}\n",
            "Statring iteration 3\n",
            "{'ner': 17600.827732211812}\n",
            "Statring iteration 4\n",
            "{'ner': 14516.906896550738}\n",
            "Statring iteration 5\n",
            "{'ner': 10964.033806758005}\n",
            "Statring iteration 6\n",
            "{'ner': 11535.556045774105}\n",
            "Statring iteration 7\n",
            "{'ner': 10664.032842613178}\n",
            "Statring iteration 8\n",
            "{'ner': 8828.792679796434}\n",
            "Statring iteration 9\n",
            "{'ner': 9942.307063860306}\n",
            "Statring iteration 10\n",
            "{'ner': 7819.600675078184}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc=nlp(train_data_clean[0][0])\n",
        "for ent in doc.ents:\n",
        "  print(f'{ent.label_.upper():{25}}- {ent.text}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqQMQuztVfIo",
        "outputId": "54fcc9d5-06ca-4b2f-9e2e-9193140a477a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME                     - Tapan kumar Nayak\n",
            "LOCATION                 - Bhubaneshwar\n",
            "EMAIL ADDRESS            - indeed.com/r/Tapan-kumar-Nayak/ da1f5ffb3c4c4b17\n",
            "YEARS OF EXPERIENCE      - 10years\n",
            "DESIGNATION              - G4S Security\n",
            "COMPANIES WORKED AT      - Infosys\n",
            "LOCATION                 - Bhubaneshwar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test the model and evaluate it\n",
        "examples = convert_json_for_spacy(\"/content/drive/MyDrive/Resume Parsing (NER + Rule-based)/testdata.json\")\n",
        "tp=0\n",
        "tr=0\n",
        "tf=0\n",
        "\n",
        "ta=0\n",
        "c=0        \n",
        "for text,annot in examples:\n",
        "\n",
        "    f=open(\"resume\"+str(c)+\".txt\",\"w\")\n",
        "    doc_to_test=nlp(text)\n",
        "    d={}\n",
        "    for ent in doc_to_test.ents:\n",
        "        d[ent.label_]=[]\n",
        "    for ent in doc_to_test.ents:\n",
        "        d[ent.label_].append(ent.text)\n",
        "\n",
        "    for i in set(d.keys()):\n",
        "\n",
        "        f.write(\"\\n\\n\")\n",
        "        f.write(i +\":\"+\"\\n\")\n",
        "        for j in set(d[i]):\n",
        "            f.write(j.replace('\\n','')+\"\\n\")\n",
        "    d={}\n",
        "    for ent in doc_to_test.ents:\n",
        "        d[ent.label_]=[0,0,0,0,0,0]\n",
        "    for ent in doc_to_test.ents:\n",
        "        doc_gold_text= nlp.make_doc(text)\n",
        "        gold = GoldParse(doc_gold_text, entities=annot.get(\"entities\"))\n",
        "        y_true = [ent.label_ if ent.label_ in x else 'Not '+ent.label_ for x in gold.ner]\n",
        "        y_pred = [x.ent_type_ if x.ent_type_ ==ent.label_ else 'Not '+ent.label_ for x in doc_to_test]  \n",
        "        if(d[ent.label_][0]==0):\n",
        "            #f.write(\"For Entity \"+ent.label_+\"\\n\")   \n",
        "            #f.write(classification_report(y_true, y_pred)+\"\\n\")\n",
        "            (p,r,f,s)= precision_recall_fscore_support(y_true,y_pred,average='weighted')\n",
        "            a=accuracy_score(y_true,y_pred)\n",
        "            d[ent.label_][0]=1\n",
        "            d[ent.label_][1]+=p\n",
        "            d[ent.label_][2]+=r\n",
        "            d[ent.label_][3]+=f\n",
        "            d[ent.label_][4]+=a\n",
        "            d[ent.label_][5]+=1\n",
        "    c+=1\n",
        "for i in d:\n",
        "    print(\"\\n For Entity \"+i+\"\\n\")\n",
        "    print(\"Accuracy : \"+str((d[i][4]/d[i][5])*100)+\"%\")\n",
        "    print(\"Precision : \"+str(d[i][1]/d[i][5]))\n",
        "    print(\"Recall : \"+str(d[i][2]/d[i][5]))\n",
        "    print(\"F-score : \"+str(d[i][3]/d[i][5]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XcFPWkIZxtj",
        "outputId": "97ef77ae-fca9-485d-ac7f-33de026f34ca"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " For Entity Name\n",
            "\n",
            "Accuracy : 99.82683982683983%\n",
            "Precision : 0.9982714019140732\n",
            "Recall : 0.9982683982683983\n",
            "F-score : 0.9979805495430495\n",
            "\n",
            " For Entity Location\n",
            "\n",
            "Accuracy : 99.3073593073593%\n",
            "Precision : 0.9931216097593915\n",
            "Recall : 0.9930735930735931\n",
            "F-score : 0.9903150762281195\n",
            "\n",
            " For Entity Email Address\n",
            "\n",
            "Accuracy : 99.48051948051948%\n",
            "Precision : 1.0\n",
            "Recall : 0.9948051948051948\n",
            "F-score : 0.9973958333333334\n",
            "\n",
            " For Entity Designation\n",
            "\n",
            "Accuracy : 100.0%\n",
            "Precision : 1.0\n",
            "Recall : 1.0\n",
            "F-score : 1.0\n",
            "\n",
            " For Entity Companies worked at\n",
            "\n",
            "Accuracy : 99.13419913419914%\n",
            "Precision : 0.9914170174135513\n",
            "Recall : 0.9913419913419913\n",
            "F-score : 0.9877533258734302\n",
            "\n",
            " For Entity College Name\n",
            "\n",
            "Accuracy : 100.0%\n",
            "Precision : 1.0\n",
            "Recall : 1.0\n",
            "F-score : 1.0\n",
            "\n",
            " For Entity Graduation Year\n",
            "\n",
            "Accuracy : 100.0%\n",
            "Precision : 1.0\n",
            "Recall : 1.0\n",
            "F-score : 1.0\n",
            "\n",
            " For Entity Skills\n",
            "\n",
            "Accuracy : 100.0%\n",
            "Precision : 1.0\n",
            "Recall : 1.0\n",
            "F-score : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ok21TIavfiQi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}